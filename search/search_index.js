var __index = {"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"<code>relaxometrynmr</code>: NMR relaxometry made easy !","text":"<p><code>relaxometrynmr</code> an open-source Python package for solid-state NMR relaxation data analysis: T1, T1<sub>\u03c1</sub> and T2.</p> <p>This package is only compatible with Bruker's NMR data (see User's guide).</p>"},{"location":"index.html#why-relaxometrynmr","title":"Why <code>relaxometrynmr</code>?","text":"<p>This package is built for NMR relaxometry data analysis and offers a user-friendly data processing. It streamlines the analysis of relaxation time constant (T1, T1<sub>\u03c1</sub> or T2) and reduces analysis time by more than 50%. It comprises several built-in modeling functions such as mono-, di-, tri-, and stretch-exponential. These functions offer the flexibility to model a wide range of relaxation behaviors -- from simple to complex systems.</p>"},{"location":"index.html#key-features","title":"Key Features","text":""},{"location":"index.html#comprehensive-nmr-data-handling","title":"Comprehensive NMR Data Handling","text":"<ul> <li>Supports mainly Bruker's data </li> <li>Handles data reading, conversion, and processing seamlessly</li> <li>Automatically detects and loads delay list (vdlist, vplist, or vclist) for relaxometry experiments</li> </ul>"},{"location":"index.html#advanced-data-processing","title":"Advanced Data Processing","text":"<ul> <li>Zero-filling for improved spectral resolution</li> <li>Phase correction (0<sup>th</sup> and 1<sup>st</sup> order) for signal representation in pure-absorption mode</li> <li>Gaussian apodisation for line broadening and improvement of signal-noise ratio</li> </ul>"},{"location":"index.html#spectral-integration","title":"Spectral Integration","text":"<ul> <li>Numerical integration methods (trapezoid and Simpson's rule) for robust quantification of peak area</li> </ul>"},{"location":"index.html#visualisation","title":"Visualisation","text":"<ul> <li>Full spectrum view for context</li> <li>Zoomed-in region for detailed analysis</li> </ul>"},{"location":"index.html#modelling-and-data-fitting","title":"Modelling and Data Fitting","text":"<ul> <li>multiple-component models: mono-, bi-, and tri-exponential functions for simple to complex relaxation</li> <li>stretched exponential models: for systems with non-standard relaxation dynamics (e.g., disordered materials)</li> <li>decay analysis: tools for analysing exponential decay curves with multiple components</li> </ul>"},{"location":"index.html#install","title":"Install","text":"<pre><code>pip install relaxometrynmr\n</code></pre>"},{"location":"index.html#dependencies","title":"Dependencies","text":"<p>The following packages are required:</p> <pre><code>nmrglue \nnumpy &gt;= 1.26.0\nmatplotlib &gt;= 3.9.0\nmrsimulator = 0.7\npydantic = 1.10\n</code></pre> <p>You can install these dependencies using pip:</p> <pre><code>pip install nmrglue numpy&gt;=1.26.0 scipy pydantic = 1.10 mrsimulator = 0.7\n</code></pre> <p>Examples can be found in User Guide</p>"},{"location":"index.html#contact","title":"Contact","text":"<p>For questions and support, please open an issue in the GitHub repository.</p>"},{"location":"about/Changelog.html","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"about/Changelog.html#mrsimulator-changes-from-v07-to-10","title":"mrsimulator changes from v0.7 to 1.0","text":""},{"location":"about/Contributors.html","title":"People","text":"<p>relaxometrynmr is written by Abdulkadir Olatunbosun Biffo.</p>"},{"location":"about/Contributors.html#active-maintainers","title":"Active Maintainers","text":"<p>The current maintainer is Abdulkadir Olatunbosun Biffo.</p>"},{"location":"about/Contributors.html#inspiration","title":"Inspiration","text":"<p>As a researcher with a focus on ion dynamics in solid-state ion-conducting materials, relaxometry is an important part of my research. Given the fact that there are quite a few custom software options I can use for relaxometry data analysis, I feel that creating a custom script will give me more flexibility and control over my data\u2014and perhaps reduce data processing and analysis time.</p> <p>Attending the 2024 PANACEA NMR summer school in Venice granted me the opportunity to meet people who have developed open-source Python packages and software (e.g., mrsimulator, mrinversion, easynmr) for NMR data analysis. I drew inspiration from my short conversation with Philip Grandinetti, who made me believe that I can create custom software suited for my needs.</p> <p>Creating this was fun, and I would like to appreciate my PhD supervisor Pedro Braga Groszewicz for giving the needed support\u2014he is such an amazing person and a great mentor!</p>"},{"location":"about/Contributors.html#credits","title":"Credits","text":"<p>I would like to thank the creator of NMRglue for making it possible to work directly with Bruker's folder. Also, a special thanks to the creator(s) of mrsimulator.</p> <p>A shoutout to my colleagues who allowed me to test this package with their data: Pranav Karanth and Tian Gu.</p>"},{"location":"about/License.html","title":"License","text":"<p>MIT License</p> <p>Copyright \u00a9 2024</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"installation/install.html","title":"Installation","text":"<p>If you have Python and pip installed, you can install <code>relaxomterynmr</code> with the command below:</p> <pre><code>pip install relaxometrynmr\n</code></pre> <p>All dependencies in <code>pyproject.toml</code> file are automatically installed</p> <p>To verify that the package has been installed, run the command below in a Python console</p> <pre><code>import relaxometrynmr\n</code></pre>"},{"location":"reference/SUMMARY.html","title":"SUMMARY","text":"<ul> <li>relaxometrynmr<ul> <li>core</li> </ul> </li> </ul>"},{"location":"reference/relaxometrynmr/core.html","title":"core","text":""},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core","title":"relaxometrynmr.core","text":""},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions","title":"T1Functions","text":"<pre><code>T1Functions(file_path)\n</code></pre> <p>A comprehensive class for processing and analyzing relaxation NMR data from Bruker format. This class provides tools for data conversion, processing, visualization, and fitting of relaxation data. It supports various fitting models including mono-, bi-, and tri-exponential functions, as well as stretched exponentials for complex relaxation behavior analysis.</p> <p>Args:     file_path (str):      Path to the Bruker NMR data directory containing the FID and acquisition      parameters.     The directory should contain standard Bruker files (fid, acqu, acqus, etc.)</p> Source code in <code>src/relaxometrynmr/core.py</code> <pre><code>def __init__(self, file_path):\n\n    \"\"\"\n    Initialize T1Functions with a path to Bruker NMR data.\n\n    Args:\n        file_path (str): \n        Path to the Bruker NMR data directory containing the FID and acquisition \n        parameters.\n        The directory should contain standard Bruker files (fid, acqu, acqus, etc.)\n    \"\"\"\n    self.file_path = file_path\n</code></pre>"},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions.file_path","title":"file_path  <code>instance-attribute</code>","text":"<pre><code>file_path = file_path\n</code></pre>"},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions.di_expdec","title":"di_expdec","text":"<pre><code>di_expdec(t, T1, T2, A, C, D)\n</code></pre> <p>Two-component exponential decay function for complex T1 relaxation analysis. This model combines two independent decay processes, following the equation: M(t) = A*[C*exp(-t/T1) + D*exp(-t/T2)]</p> <p>Useful for analyzing: - Two-phase systems - Materials with distinct mobility regions - Systems with both surface and bulk relaxation - Heterogeneous materials with two distinct environments</p> <p>Args:     t (ndarray): Time points of the decay curve     T1, T2 (float): Relaxation time constants for each component     A (float): Overall amplitude scaling factor     C, D (float): Individual component scaling factors</p> <p>Returns:     ndarray: Combined decay values from both components</p> Source code in <code>src/relaxometrynmr/core.py</code> <pre><code>def di_expdec(self, t, T1, T2, A, C, D):\n    \"\"\"\n    Two-component exponential decay function for complex T1 relaxation analysis.\n    This model\n    combines two independent decay processes, following the equation:\n    M(t) = A*[C*exp(-t/T1) + D*exp(-t/T2)]\n\n    Useful for analyzing:\n    - Two-phase systems\n    - Materials with distinct mobility regions\n    - Systems with both surface and bulk relaxation\n    - Heterogeneous materials with two distinct environments\n\n    Args:\n        t (ndarray): Time points of the decay curve\n        T1, T2 (float): Relaxation time constants for each component\n        A (float): Overall amplitude scaling factor\n        C, D (float): Individual component scaling factors\n\n    Returns:\n        ndarray: Combined decay values from both components\n    \"\"\"\n\n    return A * (((C)*np.exp(-t/T1)) + ((D)*np.exp(-t/T2)))\n</code></pre>"},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions.di_satrec_func","title":"di_satrec_func","text":"<pre><code>di_satrec_func(t, M0, T1, A, M1, T2)\n</code></pre> <p>Two-component saturation recovery function for T1 fitting.  This model describes systems with two distinct populations of spins, each with its own relaxation time constant. The function follows the equation: M(t) = A*[M0*(1 - exp(-t/T1)) + M1*(1 - exp(-t/T2))]</p> <p>This model is useful for heterogeneous systems, such as: - Different chemical environments in solids - Multiple phases in materials - Systems with distinct mobility regions</p> <p>Args:     t (ndarray): Time points of the relaxation curve     M0, M1 (float): Equilibrium magnetizations for each component     T1, T2 (float): Relaxation time constants for each component     A (float): Overall scaling factor</p> <p>Returns:     ndarray: Combined magnetization values from both components</p> Source code in <code>src/relaxometrynmr/core.py</code> <pre><code>def di_satrec_func(self, t, M0, T1, A, M1, T2):\n    \"\"\"\n    Two-component saturation recovery function for T1 fitting. \n    This model describes systems\n    with two distinct populations of spins, each with its own relaxation time constant.\n    The function follows the equation:\n    M(t) = A*[M0*(1 - exp(-t/T1)) + M1*(1 - exp(-t/T2))]\n\n    This model is useful for heterogeneous systems, such as:\n    - Different chemical environments in solids\n    - Multiple phases in materials\n    - Systems with distinct mobility regions\n\n    Args:\n        t (ndarray): Time points of the relaxation curve\n        M0, M1 (float): Equilibrium magnetizations for each component\n        T1, T2 (float): Relaxation time constants for each component\n        A (float): Overall scaling factor\n\n    Returns:\n        ndarray: Combined magnetization values from both components\n    \"\"\"\n    return A* ( (M0 * (1 - np.exp(-t / T1))) + (M1 * (1 - np.exp(-t / T2))) )\n</code></pre>"},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions.first_order_phasing","title":"first_order_phasing","text":"<pre><code>first_order_phasing(data, ph1)\n</code></pre> <p>Apply first-order phase correction to NMR data. First-order phasing applies a frequency-dependent phase correction that varies linearly across the spectrum. This corrects for delays between excitation and detection, digital filtering effects, and other instrumental factors that can cause frequency-dependent phase errors.</p> <p>Args:     data (ndarray): Complex input NMR data array, typically in the frequency domain     ph1 (float): First-order phase correction factor.      This determines the slope of the                 phase correction across the spectrum.                  The actual phase correction at each                 point is ph1 * frequency</p> <p>Returns:     ndarray: Phase-corrected complex data array with     frequency-dependent phase adjustment</p> Source code in <code>src/relaxometrynmr/core.py</code> <pre><code>def first_order_phasing(self, data, ph1):\n    \"\"\"\n    Apply first-order phase correction to NMR data.\n    First-order phasing applies a frequency-dependent\n    phase correction that varies linearly across the spectrum.\n    This corrects for delays between\n    excitation and detection, digital filtering effects,\n    and other instrumental factors that can\n    cause frequency-dependent phase errors.\n\n    Args:\n        data (ndarray): Complex input NMR data array, typically in the frequency domain\n        ph1 (float): First-order phase correction factor. \n        This determines the slope of the\n                    phase correction across the spectrum. \n                    The actual phase correction at each\n                    point is ph1 * frequency\n\n    Returns:\n        ndarray: Phase-corrected complex data array with\n        frequency-dependent phase adjustment\n    \"\"\"\n    n = data.shape[0]\n    ppm = np.linspace(-n//2, n//2, n)\n\n    phase = np.deg2rad(ph1*ppm)\n\n    phased_data = data * np.exp(1j * phase)\n\n    return phased_data\n</code></pre>"},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions.integrate_spectrum_region","title":"integrate_spectrum_region","text":"<pre><code>integrate_spectrum_region(exp_spectrum, ppm_start, ppm_end)\n</code></pre> <p>Calculate integrated intensity of a spectral region using multiple numerical integration methods.  This function provides robust integration by comparing different numerical integration techniques (trapezoid and Simpson's rules) and estimating the uncertainty in the integration. This is particularly useful for quantitative NMR analysis and relaxation measurements.</p> <p>Args:     exp_spectrum (ndarray): Input frequency-domain NMR spectrum     ppm_start (float): Starting chemical shift in ppm for the integration region     ppm_end (float): Ending chemical shift in ppm for the integration region</p> <p>Returns:     tuple: A comprehensive set of integration results:         - trapezoid integration value         - Simpson's rule integration value         - x coordinates of the integrated region         - y coordinates of the integrated region         - estimated integration uncertainty (difference between methods)</p> Source code in <code>src/relaxometrynmr/core.py</code> <pre><code>def integrate_spectrum_region(self, exp_spectrum, ppm_start, ppm_end):\n    \"\"\"\n    Calculate integrated intensity of a spectral region using multiple\n    numerical integration\n    methods. \n    This function provides robust integration by comparing different numerical\n    integration techniques\n    (trapezoid and Simpson's rules) and estimating the uncertainty\n    in the integration.\n    This is particularly useful for quantitative NMR analysis and\n    relaxation measurements.\n\n    Args:\n        exp_spectrum (ndarray): Input frequency-domain NMR spectrum\n        ppm_start (float): Starting chemical shift in ppm for the integration region\n        ppm_end (float): Ending chemical shift in ppm for the integration region\n\n    Returns:\n        tuple: A comprehensive set of integration results:\n            - trapezoid integration value\n            - Simpson's rule integration value\n            - x coordinates of the integrated region\n            - y coordinates of the integrated region\n            - estimated integration uncertainty (difference between methods)\n    \"\"\"\n    # Convert the ppm range to indices\n    ppm_scale = exp_spectrum.dimensions[0].coordinates.value\n\n    # Create a mask for the region of interest\n    region_mask = (ppm_scale &gt;= ppm_start) &amp; (ppm_scale &lt;= ppm_end)\n\n    # Extract the region of interest\n    x_region = ppm_scale[region_mask]\n    y_real = exp_spectrum.dependent_variables[0].components[0].real\n    y_region = y_real[region_mask]\n\n    # Calculate integrated intensity using trapezoid and Simpson's rule methods\n    integrated_intensity_trapz = trapezoid(y=y_region, x=x_region)\n    integrated_intensity_simps = simpson(y=y_region, x=x_region)\n    # integrated_intensity_romb = romb(y=y_region, dx=x_region[1]-x_region[0])\n    integrated_uncertainty = abs(integrated_intensity_trapz - integrated_intensity_simps)\n\n    return integrated_intensity_trapz, integrated_intensity_simps, x_region, y_region, integrated_uncertainty\n</code></pre>"},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions.mono_expdec","title":"mono_expdec","text":"<pre><code>mono_expdec(t, T1, A, B, C)\n</code></pre> <p>Single-component exponential decay function for T1 relaxation analysis. This model describes the decay of magnetization following inversion or saturation, following the equation: M(t) = A*[C*exp(-t/T1) + C]</p> <p>This is the simplest decay model, appropriate for: - Homogeneous samples - Simple liquids - Systems with a single relaxation environment</p> <p>Args:     t (ndarray): Time points of the decay curve     T1 (float): Relaxation time constant     A (float): Overall amplitude scaling factor     C (float): Equilibrium offset</p> <p>Returns:     ndarray: Exponential decay values at each time point</p> Source code in <code>src/relaxometrynmr/core.py</code> <pre><code>def mono_expdec(self, t, T1, A, B, C):\n    \"\"\"\n    Single-component exponential decay function for T1 relaxation analysis. This model\n    describes the decay of magnetization following inversion or saturation, following\n    the equation:\n    M(t) = A*[C*exp(-t/T1) + C]\n\n    This is the simplest decay model, appropriate for:\n    - Homogeneous samples\n    - Simple liquids\n    - Systems with a single relaxation environment\n\n    Args:\n        t (ndarray): Time points of the decay curve\n        T1 (float): Relaxation time constant\n        A (float): Overall amplitude scaling factor\n        C (float): Equilibrium offset\n\n    Returns:\n        ndarray: Exponential decay values at each time point\n    \"\"\"\n\n    return A * ((B)*np.exp(-t/T1)) + C\n</code></pre>"},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions.mono_satrec_func","title":"mono_satrec_func","text":"<pre><code>mono_satrec_func(t, M0, T1, A, B)\n</code></pre> <p>Single-component saturation recovery function for T1 fitting. This model describes the simplest case of longitudinal relaxation where a single population of spins returns to equilibrium following an exponential recovery. It follows the equation: M(t) = A*M0*(1 - exp(-t/T1)) + B</p> <p>This model is appropriate for systems with a single well-defined relaxation process, such as pure liquids or mobile species in solution.</p> <p>Args:     t (ndarray): Time points of the relaxation curve     M0 (float): Equilibrium magnetization     T1 (float): Spin-lattice relaxation time constant     A (float): Scaling factor for the overall amplitude     B (float): Baseline offset</p> <p>Returns:     ndarray: Calculated magnetization values at each time point</p> Source code in <code>src/relaxometrynmr/core.py</code> <pre><code>def mono_satrec_func(self, t, M0, T1, A, B):\n    \"\"\"\n    Single-component saturation recovery function for T1 fitting.\n    This model describes\n    the simplest case of longitudinal relaxation where a single population of spins\n    returns to equilibrium following an exponential recovery. It follows the equation:\n    M(t) = A*M0*(1 - exp(-t/T1)) + B\n\n    This model is appropriate for systems with a single well-defined relaxation process,\n    such as pure liquids or mobile species in solution.\n\n    Args:\n        t (ndarray): Time points of the relaxation curve\n        M0 (float): Equilibrium magnetization\n        T1 (float): Spin-lattice relaxation time constant\n        A (float): Scaling factor for the overall amplitude\n        B (float): Baseline offset\n\n    Returns:\n        ndarray: Calculated magnetization values at each time point\n    \"\"\"\n    return A*M0 * (1 - np.exp(-t / T1)) + B\n</code></pre>"},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions.plot_spectra_and_zoomed_regions","title":"plot_spectra_and_zoomed_regions","text":"<pre><code>plot_spectra_and_zoomed_regions(exp_spectra, x_regions, y_regions, xlim1, xlim2)\n</code></pre> <p>Create publication-quality plots of NMR spectra with both full view and zoomed regions. This visualization function creates a two-panel figure showing: 1. The full spectrum for context 2. A zoomed view of specific regions of interest</p> <p>The zoomed regions can be highlighted for emphasis, making it easy to focus on specific spectral features while maintaining the context of the full spectrum.</p> <p>Args:     exp_spectra (list): List of processed NMR spectra to display     x_regions (list): X coordinates for each region to be highlighted     y_regions (list): Y coordinates for each highlighted region     xlim1 (float): Lower chemical shift limit for the zoomed view (in ppm)     xlim2 (float): Upper chemical shift limit for the zoomed view (in ppm)</p> <p>Returns:     list: Maximum intensities from each spectrum, useful for normalization          and comparison between spectra</p> Source code in <code>src/relaxometrynmr/core.py</code> <pre><code>def plot_spectra_and_zoomed_regions(self, exp_spectra, x_regions, y_regions, xlim1, xlim2):\n    \"\"\"\n    Create publication-quality plots of\n    NMR spectra with both full view and zoomed regions.\n    This visualization function creates a two-panel figure showing:\n    1. The full spectrum for context\n    2. A zoomed view of specific regions of interest\n\n    The zoomed regions can be highlighted for emphasis, making it easy to focus on\n    specific spectral features while maintaining the context of the full spectrum.\n\n    Args:\n        exp_spectra (list): List of processed NMR spectra to display\n        x_regions (list): X coordinates for each region to be highlighted\n        y_regions (list): Y coordinates for each highlighted region\n        xlim1 (float): Lower chemical shift limit for the zoomed view (in ppm)\n        xlim2 (float): Upper chemical shift limit for the zoomed view (in ppm)\n\n    Returns:\n        list: Maximum intensities from each spectrum, useful for normalization\n             and comparison between spectra\n    \"\"\"\n    intensities = []\n\n\n    for i, exp_spectrum in enumerate(exp_spectra):\n        # if i == 0:\n        fig, ax = plt.subplots(1, 2, figsize=(9, 3.5), subplot_kw={\"projection\": \"csdm\"})\n\n        ax[0].plot(exp_spectrum.real)\n        ax[0].set_title(f\"Full Spectrum {i}\")\n        ax[0].invert_xaxis()\n        ax[1].plot(exp_spectrum.real, label=\"real\")\n        ax[1].fill_between(x_regions[i], y_regions[i], color='red', alpha=0.5)\n        ax[1].set_title(f\"Zoomed Spectrum {i}\")\n        ax[1].invert_xaxis()\n        ax[1].set_xlim(xlim1, xlim2) #make this modular by passing x_lim as a parameter\n\n        intensity = np.abs(exp_spectrum.dependent_variables[0].components[0].max())\n        intensities.append(intensity)\n\n        plt.tight_layout()\n        plt.legend()\n        plt.show()\n        plt.clf()\n        plt.close()\n\n\n    return intensities\n</code></pre>"},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions.process_spectrum","title":"process_spectrum","text":"<pre><code>process_spectrum(spectrum, fwhm, zero_fill_factor, ph0, ph1)\n</code></pre> <p>Process NMR spectrum with a comprehensive set of standard NMR data processing steps. This function applies, in order: 1. Gaussian apodization for line broadening and S/N improvement 2. Zero-filling for increased digital resolution 3. Fourier transformation to convert from time to frequency domain 4. Phase corrections (both zero- and first-order) 5. Conversion to ppm scale for chemical shift referencing</p> <p>Args:     spectrum (ndarray): Input time-domain NMR spectrum (FID)     fwhm (float): Full width at half maximum for Gaussian apodization in Hz.                  Controls the trade-off between resolution and signal-to-noise     zero_fill_factor (int): Factor for zero filling, typically 2-4 for moderate                            resolution enhancement     ph0 (float): Zero-order phase correction in degrees     ph1 (float): First-order phase correction factor</p> <p>Returns:     ndarray: Fully processed frequency-domain spectrum referenced to ppm scale</p> Source code in <code>src/relaxometrynmr/core.py</code> <pre><code>def process_spectrum(self, spectrum, fwhm, zero_fill_factor, ph0, ph1):\n    \"\"\"\n    Process NMR spectrum with a comprehensive set of\n    standard NMR data processing steps.\n    This function applies, in order:\n    1. Gaussian apodization for line broadening and S/N improvement\n    2. Zero-filling for increased digital resolution\n    3. Fourier transformation to convert from time to frequency domain\n    4. Phase corrections (both zero- and first-order)\n    5. Conversion to ppm scale for chemical shift referencing\n\n    Args:\n        spectrum (ndarray): Input time-domain NMR spectrum (FID)\n        fwhm (float): Full width at half maximum for Gaussian apodization in Hz.\n                     Controls the trade-off between resolution and signal-to-noise\n        zero_fill_factor (int): Factor for zero filling, typically 2-4 for moderate\n                               resolution enhancement\n        ph0 (float): Zero-order phase correction in degrees\n        ph1 (float): First-order phase correction factor\n\n    Returns:\n        ndarray: Fully processed frequency-domain spectrum referenced to ppm scale\n    \"\"\"\n    # Apply line broadening and Fourier transform\n\n    ft = sp.SignalProcessor(operations=[sp.apodization.Gaussian(FWHM=fwhm), sp.FFT()])\n\n    # Apply zero filling\n    spectrum = self.zero_fill(spectrum, zero_fill_factor * spectrum.shape[0])\n\n    # Apply first order phasing\n    exp_spectrum = self.zero_order_phasing(spectrum, ph0)\n\n    # Apply operations from the signal processor\n    exp_spectrum = ft.apply_operations(dataset=exp_spectrum)\n\n    # Apply second order phasing\n    exp_spectrum = self.first_order_phasing(exp_spectrum, ph1)\n\n    # Convert to ppm\n    exp_spectrum.dimensions[0].to(\"ppm\", \"nmr_frequency_ratio\")\n\n    return exp_spectrum\n</code></pre>"},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions.read_and_convert_bruker_data","title":"read_and_convert_bruker_data","text":"<pre><code>read_and_convert_bruker_data(save_nmrpipe=True)\n</code></pre> <p>Read and convert Bruker NMR data to NMRPipe and CSDM formats.  This function handles the complex process of importing raw Bruker data,  interpreting the acquisition parameters, and converting the data into formats suitable for further analysis.  It automatically detects and loads the variable delay list (vdlist, vplist, or vclist) used in the experiment.</p> <p>Args:     save_nmrpipe (bool): Whether to save the converted NMRPipe data to disk.      NMRPipe format is widely used in the NMR community and      can be processed with various                         third-party tools.</p> <p>Returns:     tuple: A tuple containing three elements:         - list of 1D spectra: Each element              is a single FID from the pseudo-2D dataset         - variable delay list: The time delays used in the T1 experiment         - CSDM dataset: The complete dataset in CSDM format for advanced processing</p> <p>Raises:     FileNotFoundError: If no variable delay list file                          (vdlist, vplist, or vclist) is found                             in the Bruker data directory</p> Source code in <code>src/relaxometrynmr/core.py</code> <pre><code>def read_and_convert_bruker_data(self, save_nmrpipe=True):\n\n    \"\"\"\n    Read and convert Bruker NMR data to NMRPipe and CSDM formats. \n    This function handles the complex\n    process of importing raw Bruker data, \n    interpreting the acquisition parameters, and converting\n    the data into formats suitable for further analysis. \n    It automatically detects and loads the\n    variable delay list (vdlist, vplist, or vclist) used in the experiment.\n\n    Args:\n        save_nmrpipe (bool): Whether to save the converted NMRPipe data to disk. \n        NMRPipe format is widely used in the NMR community and \n        can be processed with various\n                            third-party tools.\n\n    Returns:\n        tuple: A tuple containing three elements:\n            - list of 1D spectra: Each element \n                is a single FID from the pseudo-2D dataset\n            - variable delay list: The time delays used in the T1 experiment\n            - CSDM dataset: The complete dataset in CSDM format for advanced processing\n\n    Raises:\n        FileNotFoundError: If no variable delay list file \n                            (vdlist, vplist, or vclist) is found\n                                in the Bruker data directory\n    \"\"\"\n    # Read Bruker data\n    dic, data = ng.bruker.read(self.file_path)\n    u = ng.bruker.guess_udic(dic, data)\n\n    # Create the converter object and initialize with Bruker data\n    C = ng.convert.converter()\n    C.from_bruker(dic, data, u)\n\n    # Optionally save NMRPipe formatted data\n    if save_nmrpipe:\n        ng.pipe.write(self.file_path + \"2d_pipe.fid\", *C.to_pipe(), overwrite=True)\n\n    # Convert to CSDM format\n    csdm_ds = C.to_csdm()\n    dim1, dim2 = csdm_ds.shape\n\n    # Extract 1D spectra from the 2D dataset\n    spectra_1d = [csdm_ds[:, i] for i in range(dim2)]\n\n    possible_files = [\"vdlist\", \"vplist\", \"vclist\"]\n\n    for filename in possible_files:\n\n        try:\n            vd_list = np.loadtxt(self.file_path + filename)\n            break\n        except OSError:\n\n            if filename == possible_files[-1]:\n                raise FileNotFoundError(\"No vdlist, vplist, or vclist file found.\")\n            continue\n\n    return spectra_1d, vd_list, csdm_ds\n</code></pre>"},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions.stretch_expdec","title":"stretch_expdec","text":"<pre><code>stretch_expdec(t, T1, A, B)\n</code></pre> <p>Stretched exponential decay function for non-standard relaxation behavior. This model accounts for systems with a continuous distribution of relaxation times, following a modified Kohlrausch-Williams-Watts (KWW) function: M(t) = A*exp[-(t/T1)^B]</p> <p>This model is particularly valuable for: - Amorphous materials - Polymers and glasses - Systems with heterogeneous dynamics - Materials with complex structural organizations - Systems with correlated relaxation processes</p> <p>The stretching exponent B characterizes the distribution width of relaxation times, with B = 1 corresponding to simple exponential decay and B &lt; 1 indicating increasing heterogeneity in the relaxation process.</p> <p>Args:     t (ndarray): Time points of the decay curve     T1 (float): Characteristic relaxation time constant     A (float): Overall amplitude scaling factor     B (float): Stretching exponent, typically between 0 and 1</p> <p>Returns:     ndarray: Stretched exponential decay values at each time point,             representing the complex relaxation behavior of the system</p> Source code in <code>src/relaxometrynmr/core.py</code> <pre><code>def stretch_expdec(self, t, T1, A, B):\n\n    \"\"\"\n    Stretched exponential decay function for non-standard relaxation behavior. This model\n    accounts for systems with a continuous distribution of relaxation times, following\n    a modified Kohlrausch-Williams-Watts (KWW) function:\n    M(t) = A*exp[-(t/T1)^B]\n\n    This model is particularly valuable for:\n    - Amorphous materials\n    - Polymers and glasses\n    - Systems with heterogeneous dynamics\n    - Materials with complex structural organizations\n    - Systems with correlated relaxation processes\n\n    The stretching exponent B characterizes the distribution width of relaxation times,\n    with B = 1 corresponding to simple exponential decay and B &lt; 1 indicating\n    increasing heterogeneity in the relaxation process.\n\n    Args:\n        t (ndarray): Time points of the decay curve\n        T1 (float): Characteristic relaxation time constant\n        A (float): Overall amplitude scaling factor\n        B (float): Stretching exponent, typically between 0 and 1\n\n    Returns:\n        ndarray: Stretched exponential decay values at each time point,\n                representing the complex relaxation behavior of the system\n    \"\"\"\n\n    return A * np.exp((-t/T1)**B)\n</code></pre>"},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions.stretch_t1_exponential","title":"stretch_t1_exponential","text":"<pre><code>stretch_t1_exponential(t, T1_star, c)\n</code></pre> <p>Stretched exponential function for non-standard T1 relaxation behavior.  This model accounts for systems with a continuous distribution of relaxation times, following the Kohlrausch-Williams-Watts (KWW) function: M(t) = 1 - exp(-(t/T1_star)^c)</p> <p>This model is particularly useful for: - Disordered systems - Glasses and polymers - Systems with complex relaxation dynamics - Materials with a distribution of correlation times</p> <p>The stretching exponent c (0 &lt; c \u2264 1) indicates the degree of deviation from simple exponential behavior, with c = 1 recovering the standard exponential case.</p> <p>Args:     t (ndarray): Time points of the relaxation curve     T1_star (float): Characteristic relaxation time     c (float): Stretching exponent, typically between 0 and 1</p> <p>Returns:     ndarray: Stretched exponential relaxation curve values</p> Source code in <code>src/relaxometrynmr/core.py</code> <pre><code>def stretch_t1_exponential(self, t, T1_star, c):\n    \"\"\"\n    Stretched exponential function for non-standard T1 relaxation behavior. \n    This model\n    accounts for systems with a continuous distribution of relaxation times,\n    following\n    the Kohlrausch-Williams-Watts (KWW) function:\n    M(t) = 1 - exp(-(t/T1_star)^c)\n\n    This model is particularly useful for:\n    - Disordered systems\n    - Glasses and polymers\n    - Systems with complex relaxation dynamics\n    - Materials with a distribution of correlation times\n\n    The stretching exponent c (0 &lt; c \u2264 1) indicates the degree of deviation from\n    simple exponential behavior, with c = 1 recovering the standard exponential case.\n\n    Args:\n        t (ndarray): Time points of the relaxation curve\n        T1_star (float): Characteristic relaxation time\n        c (float): Stretching exponent, typically between 0 and 1\n\n    Returns:\n        ndarray: Stretched exponential relaxation curve values\n    \"\"\"\n    return (1 - np.exp(-(t / T1_star)**c))\n</code></pre>"},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions.tri_expdec","title":"tri_expdec","text":"<pre><code>tri_expdec(t, T1, T2, T3, A, C, D, E)\n</code></pre> <p>Three-component exponential decay function for complex T1 relaxation analysis. This model describes systems with three distinct relaxation processes, following the equation: M(t) = A*[C*exp(-t/T1) + D*exp(-t/T2) + E*exp(-t/T3)]</p> <p>This sophisticated model is suitable for: - Highly heterogeneous materials - Multi-phase systems - Complex biological samples - Materials with multiple distinct chemical environments - Systems with multiple mobility regions</p> <p>Args:     t (ndarray): Time points of the decay curve     T1, T2, T3 (float): Relaxation time constants for each component     A (float): Overall amplitude scaling factor     C, D, E (float): Individual component scaling factors</p> <p>Returns:     ndarray: Combined decay values from all three components</p> Source code in <code>src/relaxometrynmr/core.py</code> <pre><code>def tri_expdec(self, t, T1, T2, T3, A, C, D, E):\n    \"\"\"\n    Three-component exponential decay function for complex T1 relaxation analysis.\n    This model\n    describes systems with three distinct relaxation processes, following the equation:\n    M(t) = A*[C*exp(-t/T1) + D*exp(-t/T2) + E*exp(-t/T3)]\n\n    This sophisticated model is suitable for:\n    - Highly heterogeneous materials\n    - Multi-phase systems\n    - Complex biological samples\n    - Materials with multiple distinct chemical environments\n    - Systems with multiple mobility regions\n\n    Args:\n        t (ndarray): Time points of the decay curve\n        T1, T2, T3 (float): Relaxation time constants for each component\n        A (float): Overall amplitude scaling factor\n        C, D, E (float): Individual component scaling factors\n\n    Returns:\n        ndarray: Combined decay values from all three components\n    \"\"\"\n\n    return A * (((C)*np.exp(-t/T1)) + ((D)*np.exp(-t/T2)) + ((E)*np.exp(-t/T3)))\n</code></pre>"},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions.tri_satrec_func","title":"tri_satrec_func","text":"<pre><code>tri_satrec_func(t, M0, T1, A, M1, T2, M2, T3)\n</code></pre> <p>Three-component saturation recovery function for T1 fitting.  This model handles complex systems with three distinct relaxation processes.  The function follows the equation: M(t) = A*[M0*(1 - exp(-t/T1)) + M1*(1 - exp(-t/T2)) + M2*(1 - exp(-t/T3)^2)]</p> <p>This sophisticated model is applicable to: - Complex heterogeneous materials - Multi-phase systems - Materials with distinct domains of different mobilities - Systems with both surface and bulk relaxation processes</p> <p>Args:     t (ndarray): Time points of the relaxation curve     M0, M1, M2 (float): Equilibrium magnetizations for each component     T1, T2, T3 (float): Relaxation time constants for each component     A (float): Overall scaling factor</p> <p>Returns:     ndarray: Combined magnetization values from all three components</p> Source code in <code>src/relaxometrynmr/core.py</code> <pre><code>def tri_satrec_func(self, t, M0, T1, A, M1, T2, M2, T3):\n    \"\"\"\n    Three-component saturation recovery function for T1 fitting. \n    This model handles complex\n    systems with three distinct relaxation processes. \n    The function follows the equation:\n    M(t) = A*[M0*(1 - exp(-t/T1)) + M1*(1 - exp(-t/T2)) + M2*(1 - exp(-t/T3)^2)]\n\n    This sophisticated model is applicable to:\n    - Complex heterogeneous materials\n    - Multi-phase systems\n    - Materials with distinct domains of different mobilities\n    - Systems with both surface and bulk relaxation processes\n\n    Args:\n        t (ndarray): Time points of the relaxation curve\n        M0, M1, M2 (float): Equilibrium magnetizations for each component\n        T1, T2, T3 (float): Relaxation time constants for each component\n        A (float): Overall scaling factor\n\n    Returns:\n        ndarray: Combined magnetization values from all three components\n    \"\"\"\n    return A* ( (M0 * (1 - np.exp(-t / T1))) + (M1 * (1 - np.exp(-t / T2))) + \n               (M2 * (1 - np.exp(-t / T3))**2) )\n</code></pre>"},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions.zero_fill","title":"zero_fill","text":"<pre><code>zero_fill(data, new_len)\n</code></pre> <p>Zero-fill NMR data to extend its length,  improving spectral resolution in the frequency domain. Zero-filling is a crucial preprocessing step that increases the  digital resolution of the spectrum by extending the FID with zeros.  This does not add any new information but provides interpolation in the frequency domain, resulting in smoother spectral lines.</p> <p>Args:     data (ndarray): Input NMR data array, typically a time-domain FID     new_len (int): Desired length after zero-filling.      Should be greater than the original                   data length, typically a power of 2 for efficient FFT processing</p> <p>Returns:     ndarray: Zero-filled data array with length new_len.     If new_len is less than or equal             to the current length, returns the original data unchanged</p> Source code in <code>src/relaxometrynmr/core.py</code> <pre><code>def zero_fill(self, data, new_len):\n    \"\"\"\n    Zero-fill NMR data to extend its length, \n    improving spectral resolution in the frequency domain.\n    Zero-filling is a crucial preprocessing step that increases the \n    digital resolution of the spectrum\n    by extending the FID with zeros. \n    This does not add any new information but provides interpolation\n    in the frequency domain, resulting in smoother spectral lines.\n\n    Args:\n        data (ndarray): Input NMR data array, typically a time-domain FID\n        new_len (int): Desired length after zero-filling. \n        Should be greater than the original\n                      data length, typically a power of 2 for efficient FFT processing\n\n    Returns:\n        ndarray: Zero-filled data array with length new_len.\n        If new_len is less than or equal\n                to the current length, returns the original data unchanged\n    \"\"\"\n    current_len = data.shape[0]\n    if new_len &lt;= current_len:\n        return data\n    zeros_to_add = new_len - current_len\n    return np.pad(data, (0, zeros_to_add), 'constant')\n</code></pre>"},{"location":"reference/relaxometrynmr/core.html#relaxometrynmr.core.T1Functions.zero_order_phasing","title":"zero_order_phasing","text":"<pre><code>zero_order_phasing(data, ph0)\n</code></pre> <p>Apply zero-order phase correction to NMR data. Zero-order phasing applies a constant phase adjustment across the entire spectrum, correcting for the receiver phase offset during signal acquisition. This is essential for obtaining pure absorption mode spectra and is typically the first step in phase correction.</p> <p>Args:     data (ndarray): Complex input NMR data array in either time or frequency domain     ph0 (float): Phase angle in degrees. The phase correction is applied uniformly                 across the entire spectrum. Typical values range from -180\u00b0 to +180\u00b0</p> <p>Returns:     ndarray: Phase-corrected complex data array.     The correction is applied by multiplying             the data by exp(i*\u03c6), where \u03c6 is the phase angle in radians</p> Source code in <code>src/relaxometrynmr/core.py</code> <pre><code>def zero_order_phasing(self, data, ph0):\n    \"\"\"\n    Apply zero-order phase correction to NMR data.\n    Zero-order phasing applies a constant phase\n    adjustment across the entire spectrum,\n    correcting for the receiver phase offset during\n    signal acquisition.\n    This is essential for obtaining pure absorption mode spectra and is\n    typically the first step in phase correction.\n\n    Args:\n        data (ndarray): Complex input NMR data array in either time or frequency domain\n        ph0 (float): Phase angle in degrees. The phase correction is applied uniformly\n                    across the entire spectrum. Typical values range from -180\u00b0 to +180\u00b0\n\n    Returns:\n        ndarray: Phase-corrected complex data array.\n        The correction is applied by multiplying\n                the data by exp(i*\u03c6), where \u03c6 is the phase angle in radians\n    \"\"\"\n    phase = np.deg2rad(ph0)\n\n    phased_data = data * np.exp(1j * phase)\n\n    return phased_data\n</code></pre>"},{"location":"user_guide/T1_analysis.html","title":"T1 analysis","text":"<pre><code>import sys\n\nfrom scipy.optimize import curve_fit\n\nsys.path.append(\"../../src\")\n\nfrom relaxometrynmr.core import T1Functions\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n</code></pre> <pre><code>filepath = r\"..\\..\\data\\T1_data\\1\\\\\"\n\nt1 = T1Functions(filepath)\n</code></pre> <pre><code>spectra, vd_list, csdm_ds = t1.read_and_convert_bruker_data(filepath)\n</code></pre> <pre><code>exp_spectra = []\nfor i, spectrum in enumerate(spectra):\n    if i == 1 :\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"500 Hz\", zero_fill_factor=10, ph0=70, ph1=0.55)\n        exp_spectra.append(exp_spectrum)\n    elif i == 2:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"500 Hz\", zero_fill_factor=10, ph0=100, ph1=0.55)\n        exp_spectra.append(exp_spectrum)\n\n    elif i == 5:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"500 Hz\", zero_fill_factor=10, ph0=70, ph1=0.52)\n        exp_spectra.append(exp_spectrum)\n    elif i == 6:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"500 Hz\", zero_fill_factor=10, ph0=30, ph1=0.5)\n        exp_spectra.append(exp_spectrum)\n    else:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"500 Hz\", zero_fill_factor=10, ph0=50, ph1=0.5)\n        exp_spectra.append(exp_spectrum)\n</code></pre> <pre><code>trapz_ints = []\nsimps_ints = []\nx_regions = []\ny_regions = []\nint_uncs = []\n\nfor i, exp_spectrum in enumerate(exp_spectra):\n    trapz_int, simps_int, x_region, y_region, int_unc = t1.integrate_spectrum_region(exp_spectrum, ppm_start=500, ppm_end=650)\n    trapz_ints.append(trapz_int)\n    simps_ints.append(simps_int)\n    x_regions.append(x_region)\n    y_regions.append(y_region)\n    int_uncs.append(int_unc)\n</code></pre> <pre><code>max_x_zoom = 1000\n\nmin_x_zoom = 200\n\nabs_ints = t1.plot_spectra_and_zoomed_regions(exp_spectra, x_regions, y_regions, max_x_zoom, min_x_zoom)\n</code></pre> <pre><code># vd_list imported from the file_path is converted into a numpy array\n\nvd_list = np.array(vd_list)\n\n# slicing the vd_list if some data points are missing\n\nvd_list = vd_list[:len(abs_ints)]\n\n\nsimps_ints = simps_ints[:len(vd_list)]\n\nabs_ints = abs_ints[:len(vd_list)]\n</code></pre> <pre><code>fig, ax = plt.subplots()\n\nax.scatter(vd_list, abs_ints, color='blue', label='intensity extraction')\n\n\nax.scatter(vd_list, simps_ints, color='red', label='area extraction')\n\n\nax.semilogy()\n\nax.semilogx()\n\nax.legend(loc='best', frameon=True)\n\nax.set_xlabel(r'$\\tau$ (s)')\nax.set_ylabel('Intensity (arbitrary unit)')\n\n\n\nplt.tight_layout()\n\nplt.show()\n</code></pre> <pre><code>fig, ax = plt.subplots()\n\noutput_lines = []\n\n# Define a list of tuples for the two sets of intensities\nintensity_sets = [\n    (simps_ints, 'Simps Area', 'Guess Curve', 'Fitted Curve', 'r'),\n    (abs_ints, 'Intensities', 'Guess int. Curve', 'Fitted int. curve', 'b')\n]\n\n\n# Initial guess parameters\nM0_guess = 0.9\nT1_guess = 2.8e-3\n\nfor i, (ints, label, guess_label, fitted_label, color) in enumerate(intensity_sets):\n    # here we are using the maximum intensity of each spectrum to \n    # extract the spin-lattice relaxation time, you can use the integrated area of each spectum as well by setting i == 0\n    if i == 1:\n        A_guess = np.max(ints)\n        B_guess = np.min(ints)\n\n        # Scatter plot\n        ax.scatter(vd_list, ints, color=color, label=label)\n\n        # Guess curve\n        guess_integrated_int = t1.mono_satrec_func(vd_list, M0_guess, T1_guess, A_guess, B_guess)\n        ax.plot(vd_list, guess_integrated_int, color='brown', linestyle='--', label=guess_label, alpha=0.5)\n\n        # Fit the data\n        popt, pcov = curve_fit(t1.mono_satrec_func, vd_list, ints, p0=[M0_guess, T1_guess, A_guess, B_guess])\n\n        # Save the fitted params and uncertainties\n        M0_fitted, T1_fitted, A_fitted, B_fitted = popt\n        M0_unc, T1_unc, A_unc, B_unc = np.sqrt(np.diag(pcov))\n\n        # Extract the fitted curve\n        fitted_curve = t1.mono_satrec_func(vd_list, M0_fitted, T1_fitted, A_fitted, B_fitted)\n        ax.plot(vd_list, fitted_curve, linestyle='-', color='grey', label=fitted_label)\n\n        # Print the fitted parameters and uncertainties\n        print(f'M0_{label.lower().replace(\" \", \"_\")}: {M0_fitted} \u00b1 {M0_unc}')\n        print(f'T1_{label.lower().replace(\" \", \"_\")}: {T1_fitted} \u00b1 {T1_unc}')\n        print(f'A_{label.lower().replace(\" \", \"_\")}: {A_fitted} \u00b1 {A_unc}')\n        print(f'B_{label.lower().replace(\" \", \"_\")}: {B_fitted} \u00b1 {B_unc}')\n\n        #Format the string and append fitted parameters\n\n        output_lines.append(f'M0_{label.lower().replace(\" \", \"_\")}: {M0_fitted} \u00b1 {M0_unc}\\n')\n        output_lines.append(f'T1_{label.lower().replace(\" \", \"_\")}: {T1_fitted} \u00b1 {T1_unc}\\n')\n        output_lines.append(f'A_{label.lower().replace(\" \", \"_\")}: {A_fitted} \u00b1 {A_unc}\\n')\n        output_lines.append(f'B_{label.lower().replace(\" \", \"_\")}: {B_fitted} \u00b1 {B_unc}\\n')\n        #save the fitted params and uncertainties in a text file\n        with open(filepath+'mono_exp_fitted_params.txt', 'w') as f:\n            f.writelines(output_lines)\n\nax.semilogy()\nax.semilogx()\nax.legend(loc='best', frameon=False)\nax.set_xlabel(r'$\\tau$ (s)')\nax.set_ylabel('Intensity (arbitrary unit)')\nplt.tight_layout()\nplt.savefig(filepath+'mono_exp_T1_fitting.svg', bbox_inches='tight', transparent=True)\nplt.show()\nplt.clf()\nplt.close()\n</code></pre> <pre>\n<code>M0_intensities: 0.8295563618067949 \u00b1 60049561288401.65\nT1_intensities: 0.004644172807209871 \u00b1 0.00020369617126654092\nA_intensities: 176827806117.40628 \u00b1 1.2800133504869488e+25\nB_intensities: 32856412289.666718 \u00b1 933502453.4584883\n</code>\n</pre>"},{"location":"user_guide/T1_analysis.html#import-the-necessary-libraries","title":"Import the necessary libraries","text":""},{"location":"user_guide/T1_analysis.html#specify-path-to-the-data-file-and-ensure-that-is-appended-to-the-end-of-the-path","title":"specify path to the data file and ensure that \"\\\\\" is appended to the end of the path","text":"<ul> <li>create an instance t1 of T1Functions</li> </ul>"},{"location":"user_guide/T1_analysis.html#read-and-convert-bruker-nmr-data-to-nmrpipe-and-csdm-formats-read_and_convert_bruker_data","title":"Read and convert Bruker NMR data to NMRPipe and CSDM formats: read_and_convert_bruker_data.","text":"<p>The function automatically detects and loads the variable delay list (vdlist, vplist, vclist) used in the experiment.</p> <p>It returns a tuple containing three elements: a list of 1D NMR (spectra), the variable delay list (vd_list), and the complete dataset in CSDM format (csdm_ds)</p>"},{"location":"user_guide/T1_analysis.html#process-the-returned-1d-nmr-spectra","title":"Process the returned 1D NMR spectra","text":"<ul> <li>apply the Gaussian apodisation (fwhm)</li> <li>zero-filling for increased digital resolution (zero_fill_factor)</li> <li>0<sup>th</sup> order phase correction (ph0)</li> <li>1<sup>st</sup> order phase correction (ph1) -- this phase correction is a bit nuanced and so far, a value of 0 - 0.6 \u00b0 has worked quite well: see the \"Understanding Phasing\" example under User Guide</li> <li>In applying the 1<sup>st</sup> order correction, you would have to experiment with the mentioned values to obtain a pure absorption line-shape signal</li> </ul>"},{"location":"user_guide/T1_analysis.html#find-the-area-under-the-peak-of-interest-using-the-integrate_spectrum_region-function","title":"Find the area under the peak of interest using the <code>integrate_spectrum_region()</code> function","text":"<p>The integration function employed here integrate each spectrum using trapezoid and simpson function, respectively. ppm_start and ppm_end need to be defined as the starting and ending ppm region needed to be integrated.  The integrated area of each spectrum is appended to trapz_ints and simps_ints, respectively. x_ and y_regions are regions of integration in the spectra -- needed for visuals.</p> <ul> <li>There is no difference between trapz and simps, so you would have to use either of the two in a later stage</li> </ul>"},{"location":"user_guide/T1_analysis.html#plot_spectra_and_zoom-function","title":"plot_spectra_and_zoom() function","text":"<ul> <li>creates plots of NMR spectra with both full view and zoomed regions (max and min x zoom)</li> <li>highlights the integrated x_ and y_regions on the zoomed plot</li> <li>returns maximum intensities from each spectrum (abs_ints): relevant for relaxometry just like integrated areas contained in trapz_ints and simps_ints</li> </ul>"},{"location":"user_guide/T1_analysis.html#convert-vd-list-to-numpy-array-and-ensure-that-the-list-and-extracted-intensities-and-areas-are-of-the-same-length","title":"Convert vd list to numpy array and ensure that the list and extracted intensities and areas are of the same length","text":""},{"location":"user_guide/T1_analysis.html#viusalise-the-list-and-the-extracted-intensities-and-areas","title":"Viusalise the list and the extracted intensities and areas","text":"<ul> <li>the extracted areas from either trapz or simps integration and extracted max intensities of each spectrum are plotted against corresponding time in vd_list</li> </ul>"},{"location":"user_guide/T1_analysis.html#let-us-fit-one-of-the-data-with-a-simple-exponential-satrec-function-here-we-are-using-the-intensities-the-areas-can-also-be-utilised","title":"Let us fit one of the data with a simple exponential satrec function: here we are using the intensities, the areas can also be utilised","text":""},{"location":"user_guide/T1_analysis.html#understanding-the-optimised-parameters","title":"Understanding the optimised parameters","text":"<ul> <li>M0_intensities == equilibrium magnetisation</li> <li>T1_intensities == spin-lattice relaxation time in seconds</li> <li>B_intensities == Baseline offset</li> <li>A_intensities == scaling factor for the overall amplitude</li> </ul>"},{"location":"user_guide/T1_rho_analysis.html","title":"T1 rho analysis","text":"<pre><code>import sys\n\nfrom scipy.optimize import curve_fit\n\nsys.path.append(\"../../src\")\n\nfrom relaxometrynmr.core import T1Functions\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n</code></pre> <pre><code>filepath = r\"..\\..\\data\\T1_rho_data\\79\\\\\"\n\nt1 = T1Functions(filepath)\n</code></pre> <pre><code>spectra, vd_list, csdm_ds = t1.read_and_convert_bruker_data(filepath)\n</code></pre> <pre><code>exp_spectra = []\nfor i, spectrum in enumerate(spectra):\n    if i == 0:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"1200 Hz\", zero_fill_factor=10, ph0=-25, ph1=0.005)\n        exp_spectra.append(exp_spectrum)\n    elif i == 1:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"1200 Hz\", zero_fill_factor=10, ph0=-20, ph1=0.005)\n        exp_spectra.append(exp_spectrum)\n    elif i == 2:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"1200 Hz\", zero_fill_factor=10, ph0=5, ph1=0.006)\n        exp_spectra.append(exp_spectrum)\n    elif i == 3:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"1200 Hz\", zero_fill_factor=10, ph0=5, ph1=0.004)\n        exp_spectra.append(exp_spectrum)\n    elif i == 4:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"1200 Hz\", zero_fill_factor=10, ph0=-5, ph1=0.005)\n        exp_spectra.append(exp_spectrum)\n    elif i ==5:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"1200 Hz\", zero_fill_factor=10, ph0=-5, ph1=0.006)\n        exp_spectra.append(exp_spectrum)\n    else:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"1200 Hz\", zero_fill_factor=10, ph0=-10, ph1=0.005)\n        exp_spectra.append(exp_spectrum)\n</code></pre> <pre><code>trapz_ints = []\nsimps_ints = []\nx_regions = []\ny_regions = []\nint_uncs = []\nfor i, exp_spectrum in enumerate(exp_spectra):\n    trapz_int, simps_int, x_region, y_region, int_unc = t1.integrate_spectrum_region(exp_spectrum, ppm_start=-200, ppm_end=200)\n    trapz_ints.append(trapz_int)\n    simps_ints.append(simps_int)\n    x_regions.append(x_region)\n    y_regions.append(y_region)\n    int_uncs.append(int_unc)\n</code></pre> <pre><code>max_x_zoom = 300\n\nmin_x_zoom = -300\n\nabs_ints = t1.plot_spectra_and_zoomed_regions(exp_spectra, x_regions, y_regions, max_x_zoom, min_x_zoom)\n</code></pre> <pre><code>#vd_list imported from the file_path and converted into a numpy array\n\nvd_list = np.array(vd_list)\n\n#slicing the vd_list if some data points are shitty\nvd_list = vd_list[:len(abs_ints)]\n\n#slicing the intensities if some data points are shitty\n\nsimps_ints = simps_ints[:len(vd_list)]\n\nabs_ints = abs_ints[:len(vd_list)]\n</code></pre> <pre><code>fig, ax = plt.subplots()\n\nax.scatter(vd_list, abs_ints, color='blue', label='intensity extraction')\n\n\nax.scatter(vd_list, simps_ints, color='red', label='area extraction')\n\nax.semilogy()\n\nax.semilogx()\n\nax.legend(loc='best', frameon=True)\n\nax.set_xlabel(r'$\\tau$ (s)')\nax.set_ylabel('Intensity (arbitrary unit)')\n\n\n\nplt.tight_layout()\n\nplt.show()\n</code></pre> <pre><code>#T1rho fitting of the data\nfig, ax = plt.subplots()\n\noutput_lines = []\n\n# Define a list of tuples for the two sets of intensities\n\nintensity_sets = [\n    (simps_ints, 'Simps Area', 'Guess Curve', 'Fitted Curve', 'r'),\n    (abs_ints, 'Absolute Intensities', 'Guess Abs Int Curve', 'Fitted Curve Absolute Intensity', 'b')\n]\n\n\n# Initial guess parameters\n\nT1_guess = 3347\n\nT2_guess = 34555\n\nT3_guess = 52\n\n\n\nfor i, (ints, label, guess_label, fitted_label, color) in enumerate(intensity_sets):\n    if i ==0:\n        # A_guess = np.max(ints)\n        A_guess = 1e7\n\n        B_guess = np.min(ints)\n\n        C_guess = 0.48\n\n        D_guess = 0.2\n\n        E_guess = 0.53\n\n\n        ax.scatter(vd_list, ints, color=color, marker='o', facecolors='none', label=label)\n\n        # Guess curve\n        guess_integrated_int = t1.tri_expdec(vd_list, T1_guess, T2_guess, T3_guess, A_guess, C_guess, D_guess, E_guess)\n        # guess_integrated_int = t1.expdec(vd_list, T1_guess, T2_guess, T3_guess, A_guess, B_guess)\n\n        # ax.plot(vd_list, guess_integrated_int, color='brown', linestyle='--', label=guess_label, alpha=0.9)\n\n    # Fit the data\n        popt, pcov = curve_fit(t1.tri_expdec, vd_list, ints, p0=[T1_guess, T2_guess, T3_guess, A_guess, C_guess, D_guess, E_guess])\n\n    # Save the fitted params and uncertainties\n        T1_fitted, T2_fitted, T3_fitted, A_fitted, C_fitted, D_fitted, E_fitted = popt\n        T1_unc, T2_unc, T3_unc, A_unc, C_unc, D_unc, E_unc = np.sqrt(np.diag(pcov))\n\n        #define T1 and T2\n        component_1 = A_fitted *  (C_fitted)*np.exp(-vd_list/T1_fitted)\n\n        component_2 = A_fitted * (D_fitted)*np.exp(-vd_list/T2_fitted)\n\n        component_3 = A_fitted * (E_fitted)*np.exp(-vd_list/T3_fitted) \n\n        overall_component = component_1 + component_2 + component_3\n\n    # Extract the fitted curve\n        fitted_curve = t1.tri_expdec(vd_list,T1_fitted, T2_fitted, T3_fitted, A_fitted, C_fitted, D_fitted, E_fitted)\n        ax.plot(vd_list, fitted_curve, linestyle='-', color=color, label=fitted_label)\n        ax.plot(vd_list, component_1, linestyle='--', color='black', alpha=0.5, label='component_1')\n        ax.plot(vd_list, component_2, linestyle='--', color='blue', alpha=0.5, label='component_2')\n        ax.plot(vd_list, component_3, linestyle='--', color='green', alpha=0.5, label='component_3')\n\n\n    # print the fitted parameters and uncertainties\n        print(f'T1_{label.lower().replace(\" \", \"_\")}: {T1_fitted} \u00b1 {T1_unc}')\n        print(f'T2_{label.lower().replace(\" \", \"_\")}: {T2_fitted} \u00b1 {T2_unc}')\n        print(f'T3_{label.lower().replace(\" \", \"_\")}: {T3_fitted} \u00b1 {T3_unc}')\n        print(f'A_{label.lower().replace(\" \", \"_\")}: {A_fitted} \u00b1 {A_unc}')\n        print(f'C_{label.lower().replace(\" \", \"_\")}: {C_fitted} \u00b1 {C_unc}')\n        print(f'D_{label.lower().replace(\" \", \"_\")}: {D_fitted} \u00b1 {D_unc}')\n        print(f'E_{label.lower().replace(\" \", \"_\")}: {E_fitted} \u00b1 {E_unc}')\n        print(E_fitted+C_fitted+D_fitted)\n\n\n    # #Format the string and append fitted parameters\n\n        output_lines.append(f'M0_{label.lower().replace(\" \", \"_\")}: {A_fitted} \u00b1 {A_unc}\\n')\n        output_lines.append(f'T1_{label.lower().replace(\" \", \"_\")}: {T1_fitted} \u00b1 {T1_unc}\\n')\n        output_lines.append(f'T2_{label.lower().replace(\" \", \"_\")}: {T2_fitted} \u00b1 {T2_unc}\\n')\n        output_lines.append(f'T3_{label.lower().replace(\" \", \"_\")}: {T3_fitted} \u00b1 {T3_unc}\\n')\n        output_lines.append(f'C_{label.lower().replace(\" \", \"_\")}: {C_fitted} \u00b1 {C_unc}\\n')\n        output_lines.append(f'D_{label.lower().replace(\" \", \"_\")}: {D_fitted} \u00b1 {D_unc}\\n')\n        output_lines.append(f'E_{label.lower().replace(\" \", \"_\")}: {E_fitted} \u00b1 {E_unc}\\n')\n        #save the fitted params and uncertainties in a text file\n        with open(filepath+'multi_exp_fitted_params.txt', 'w') as f:\n            f.writelines(output_lines)\n\n\nax.semilogx()\nax.legend(loc='best', frameon=False)\nax.set_xlabel(r'$\\tau$ (s)')\nax.set_ylabel('Intensity (arbitrary unit)')\n\n\n#plot the covariance matrix in another figure and label the axes with the fitted parameters\n\nplt.savefig(filepath+'multi_exp_T1_fitting.svg', bbox_inches='tight', transparent=True)\nplt.tight_layout()\nfig, ax = plt.subplots()\nim = ax.imshow(np.log(np.abs(pcov)))\nax.set_xticks(np.arange(len(popt)))\nax.set_yticks(np.arange(len(popt)))\nax.set_xticklabels(['T1', 'T2', 'T3', 'A', 'C', 'D', 'E'])\nax.set_yticklabels(['T1', 'T2', 'T3', 'A', 'C', 'D', 'E'])\nplt.colorbar(im)\nplt.show()\nplt.clf()\nplt.close()\n</code></pre> <pre>\n<code>T1_simps_area: 2632.5748197429702 \u00b1 1087.936001447381\nT2_simps_area: 32453.489646421738 \u00b1 7605.502233342903\nT3_simps_area: 22.480659331279714 \u00b1 13.62569637284241\nA_simps_area: 9937082.9955292 \u00b1 15645264532305.969\nC_simps_area: 0.5768725712907005 \u00b1 908246.7635352787\nD_simps_area: 0.9177653023241111 \u00b1 1444959.3893232432\nE_simps_area: 0.4920216632499338 \u00b1 774654.8564071889\n1.9866595368647455\n</code>\n</pre>"},{"location":"user_guide/T1_rho_analysis.html#import-the-necessary-libraries","title":"Import the necessary libraries","text":""},{"location":"user_guide/T1_rho_analysis.html#specify-path-to-the-data-file-and-ensure-that-is-appended-to-the-end-of-the-path","title":"specify path to the data file and ensure that \"\\\\\" is appended to the end of the path","text":"<ul> <li>create an instance t1 of T1Functions</li> </ul> <p>Note: This data is a T1<sub>\u03c1</sub> data</p>"},{"location":"user_guide/T1_rho_analysis.html#read-and-convert-bruker-nmr-data-to-nmrpipe-and-csdm-formats-read_and_convert_bruker_data","title":"Read and convert Bruker NMR data to NMRPipe and CSDM formats: read_and_convert_bruker_data.","text":"<p>The function automatically detects and loads the variable delay list (vdlist, vplist, vclist) used in the experiment. In this case, the vplist is loaded, but vdlist terminology will be used.</p> <p>It returns a tuple containing three elements: a list of 1D NMR (spectra), the variable delay list (vd_list), and the complete dataset in CSDM format (csdm_ds)</p>"},{"location":"user_guide/T1_rho_analysis.html#process-the-returned-1d-nmr-spectra","title":"Process the returned 1D NMR spectra","text":"<ul> <li>apply the Gaussian apodisation (fwhm)</li> <li>zero-filling for increased digital resolution (zero_fill_factor)</li> <li>0<sup>th</sup> order phase correction (ph0)</li> <li>1<sup>st</sup> order phase correction (ph1) -- this phase correction is a bit nuanced and so far, a value of 0 - 0.6 \u00b0 has worked quite well: see the \"Understanding Phasing\" example under User Guide</li> <li>In applying the 1<sup>st</sup> order correction, you would have to experiment with the mentioned values to obtain a pure absorption line-shape signal</li> </ul>"},{"location":"user_guide/T1_rho_analysis.html#find-the-area-under-the-peak-of-interest-using-the-integrate_spectrum_region-function","title":"Find the area under the peak of interest using the <code>integrate_spectrum_region()</code> function","text":"<p>The integration function employed here integrate each spectrum using trapezoid and simpson function, respectively. ppm_start and ppm_end need to be defined as the starting and ending ppm region needed to be integrated.  The integrated area of each spectrum is appended to trapz_ints and simps_ints, respectively. x_ and y_regions are regions of integration in the spectra -- needed for visuals.</p> <ul> <li>There is no difference between trapz and simps, so you would have to use either of the two in a later stage</li> </ul>"},{"location":"user_guide/T1_rho_analysis.html#plot_spectra_and_zoom-function","title":"plot_spectra_and_zoom() function","text":"<ul> <li>creates plots of NMR spectra with both full view and zoomed regions (max and min x zoom)</li> <li>highlights the integrated x_ and y_regions on the zoomed plot</li> <li>returns maximum intensities from each spectrum (abs_ints): relevant for relaxometry just like integrated areas contained in trapz_ints and simps_ints</li> </ul>"},{"location":"user_guide/T1_rho_analysis.html#convert-vd-list-to-numpy-array-and-ensure-that-the-list-and-extracted-intensities-and-areas-are-of-the-same-length","title":"Convert vd list to numpy array and ensure that the list and extracted intensities and areas are of the same length","text":""},{"location":"user_guide/T1_rho_analysis.html#viusalise-the-list-and-the-extracted-intensities-and-areas","title":"Viusalise the list and the extracted intensities and areas","text":"<ul> <li>the extracted areas from either trapz or simps integration and extracted max intensities of each spectrum are plotted against corresponding time in vd_list</li> </ul>"},{"location":"user_guide/T1_rho_analysis.html#let-us-fit-one-of-the-data-with-a-tri-expdec-function-here-we-are-using-the-area-the-intesities-can-also-be-utilised","title":"Let us fit one of the data with a tri-expdec function: here we are using the area, the intesities can also be utilised","text":"<p>This choice of fitting is because the system has multiple relaxation times and so far 3 distinct relaxation behaviours have been identified -- so the choice of using tri-expdec</p>"},{"location":"user_guide/T2_cpmg_analysis.html","title":"T2 cpmg analysis","text":"<pre><code>import sys\n\nfrom scipy.optimize import curve_fit\n\nsys.path.append(\"../../src\")\n\nfrom relaxometrynmr.core import T1Functions\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n</code></pre> <pre><code>filepath = r\"..\\..\\data\\T2_cpmg_data\\38\\\\\"\n\nt1 = T1Functions(filepath)\n</code></pre> <pre><code>spectra, vd_list, csdm_ds = t1.read_and_convert_bruker_data(filepath)\n</code></pre> <pre><code>exp_spectra = []\nfor i, spectrum in enumerate(spectra):\n\n    if i == 0:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"50 Hz\", zero_fill_factor=10, ph0=285, ph1=0.195)\n        exp_spectra.append(exp_spectrum)\n    elif i == 1:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"50 Hz\", zero_fill_factor=10, ph0=295, ph1=0.1948)\n        exp_spectra.append(exp_spectrum)\n    elif i == 2:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"50 Hz\", zero_fill_factor=10, ph0=290, ph1=0.1948)\n        exp_spectra.append(exp_spectrum)\n    elif i == 3:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"50 Hz\", zero_fill_factor=10, ph0=285, ph1=0.195)\n        exp_spectra.append(exp_spectrum)\n    elif i == 4:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"50 Hz\", zero_fill_factor=10, ph0=280, ph1=0.195)\n        exp_spectra.append(exp_spectrum)\n    elif i == 5:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"50 Hz\", zero_fill_factor=10, ph0=280, ph1=0.1948)\n        exp_spectra.append(exp_spectrum)\n    elif i == 6:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"50 Hz\", zero_fill_factor=10, ph0=290, ph1=0.1948)\n        exp_spectra.append(exp_spectrum)\n    elif i == 7:\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"50 Hz\", zero_fill_factor=10, ph0=290, ph1=0.195)\n        exp_spectra.append(exp_spectrum)\n    else :\n        exp_spectrum = t1.process_spectrum(spectrum, fwhm=\"50 Hz\", zero_fill_factor=10, ph0=292, ph1=0.1948)\n        exp_spectra.append(exp_spectrum)\n</code></pre> <pre><code>trapz_ints = []\nsimps_ints = []\nx_regions = []\ny_regions = []\nint_uncs = []\nfor i, exp_spectrum in enumerate(exp_spectra):\n    trapz_int, simps_int, x_region, y_region, int_unc = t1.integrate_spectrum_region(exp_spectrum, \n                                                                                     ppm_start=-15, ppm_end=15)\n    trapz_ints.append(trapz_int)\n    simps_ints.append(simps_int)\n    x_regions.append(x_region)\n    y_regions.append(y_region)\n    int_uncs.append(int_unc)\n</code></pre> <pre><code>max_x_zoom = 20\n\nmin_x_zoom = -20\n\nabs_ints = t1.plot_spectra_and_zoomed_regions(exp_spectra, x_regions, y_regions, max_x_zoom, min_x_zoom)\n</code></pre> <pre><code># Enter your D2 or D20 value in the variable D2\n\nD2 = 4.86e-6\n\n#vd_list imported from the file_path and converted into a numpy array\n\nvd_list = np.array(vd_list)\n\nvd_list = vd_list * 2 * D2\n\n# slicing the vd_list if some data points are missing\n\nsimps_ints = simps_ints[:len(vd_list)]\n\nabs_ints = abs_ints[:len(vd_list)]\n</code></pre> <pre><code>fig, ax = plt.subplots()\n\nax.scatter(vd_list, abs_ints, color='blue', label='intensity extraction')\n\n\nax.scatter(vd_list, simps_ints, color='red', label='area extraction')\n# ax.errorbar(vd_list, simps_ints, yerr=int_uncs, fmt='o', color='red', label='error')\n\n# ax.semilogy()\n\nax.semilogx()\n\nax.legend(loc='best', frameon=True)\n\nax.set_xlabel(r'$\\tau$ (s)')\nax.set_ylabel('Intensity (arbitrary unit)')\n\n\n\nplt.tight_layout()\n\nplt.show()\n</code></pre> <pre><code>#T1rho fitting\n\nfig, ax = plt.subplots()\noutput_lines = []\n# Define a list of tuples for the two sets of intensities\nintensity_sets = [\n    (simps_ints, 'Simps Area', 'Guess Curve', 'Fitted Curve', 'r'),\n    (abs_ints, 'Absolute Intensities', 'Guess Abs Int Curve', 'Fitted Curve Absolute Intensity', 'b')\n]\n\n\n# Initial guess parameters\n\nT1_guess = 10.6 * 10**-3\n\n\n\n\n\nfor i, (ints, label, guess_label, fitted_label, color) in enumerate(intensity_sets):\n    if i ==0:\n        # A_guess = np.max(ints)\n        A_guess = 747197159\n\n        B_guess = 43\n\n        C_guess = np.min(ints)\n\n\n\n    # Scatter plot\n        # ax.scatter(vd_list, ints, color=color, label=label)\n    #scatter plot with marker having no face color\n        ax.scatter(vd_list, ints, color=color, marker='o', facecolors='none', label=label)\n\n    # Guess curve\n        guess_integrated_int = t1.mono_expdec(vd_list, T1_guess, A_guess, B_guess, C_guess)\n        # guess_integrated_int = t1.expdec(vd_list, T1_guess, T2_guess, T3_guess, A_guess, B_guess)\n\n        # ax.plot(vd_list, guess_integrated_int, color='brown', linestyle='--', label=guess_label, alpha=0.9)\n\n    # Fit the data\n        popt, pcov = curve_fit(t1.mono_expdec, vd_list, ints, p0=[T1_guess, A_guess, B_guess, C_guess])\n\n    # Save the fitted params and uncertainties\n        T1_fitted, A_fitted, B_fitted, C_fitted = popt\n        T1_unc, A_unc, B_unc, C_unc = np.sqrt(np.diag(pcov))\n\n        #define T1 and T2\n        component_1 = A_fitted *  (B_fitted)*np.exp(-vd_list/T1_fitted) + C_fitted\n\n\n\n    # Extract the fitted curve\n\n        fitted_curve = t1.mono_expdec(vd_list,T1_fitted, A_fitted, B_fitted, C_fitted)\n        ax.plot(vd_list, fitted_curve, linestyle='-', color=color, label=fitted_label)\n        # ax.scatter(vd_list, fitted_curve, color='black', marker='o', facecolors='none', label=fitted_label)\n        ax.plot(vd_list, component_1, linestyle='--', color='black', alpha=0.5, label='component_1')\n\n\n\n\n    # print the fitted parameters and uncertainties\n        print(f'T1_{label.lower().replace(\" \", \"_\")}: {T1_fitted} \u00b1 {T1_unc}')\n\n\n        print(f'A_{label.lower().replace(\" \", \"_\")}: {A_fitted} \u00b1 {A_unc}')\n        print(f'B_{label.lower().replace(\" \", \"_\")}: {B_fitted} \u00b1 {B_unc}')\n        print(f'C_{label.lower().replace(\" \", \"_\")}: {C_fitted} \u00b1 {C_unc}')\n\n\n    # #Format the string and append fitted parameters\n\n        output_lines.append(f'M0_{label.lower().replace(\" \", \"_\")}: {A_fitted} \u00b1 {A_unc}\\n')\n        output_lines.append(f'T1_{label.lower().replace(\" \", \"_\")}: {T1_fitted} \u00b1 {T1_unc}\\n')\n\n\n        output_lines.append(f'B_{label.lower().replace(\" \", \"_\")}: {B_fitted} \u00b1 {B_unc}\\n')\n        output_lines.append(f'C_{label.lower().replace(\" \", \"_\")}: {C_fitted} \u00b1 {C_unc}\\n')\n\n        #save the fitted params and uncertainties in a text file\n        with open(filepath+'mono_exp_fitted_params.txt', 'w') as f:\n            f.writelines(output_lines)\n\n\n# ax.semilogy()\nax.semilogx()\nax.legend(loc='best', frameon=False)\nax.set_xlabel(r'$\\tau$ (s)')\nax.set_ylabel('Intensity (arbitrary unit)')\n\n\n#plot the covariance matrix in another figure and label the axes with the fitted parameters\n\n\nplt.savefig(filepath+'mono_exp_T1_fitting.svg', bbox_inches='tight', transparent=True)\nplt.tight_layout()\nfig, ax = plt.subplots()\nim = ax.imshow(np.log(np.abs(pcov)))\nax.set_xticks(np.arange(len(popt)))\nax.set_yticks(np.arange(len(popt)))\nax.set_xticklabels(['T1', 'A', 'B', 'C'])\nax.set_yticklabels(['T1', 'A', 'B', 'C'])\nplt.colorbar(im)\nplt.show()\nplt.clf()\nplt.close()\n</code></pre> <pre>\n<code>T1_simps_area: 0.00010217635214086735 \u00b1 2.1174008518649647e-05\nA_simps_area: 1604701008.464661 \u00b1 2.355204036413354e+16\nB_simps_area: 31.574675822333777 \u00b1 463975120.531155\nC_simps_area: 2999344350.029867 \u00b1 1426611309.6305165\n</code>\n</pre> <p>From the fit above, it is evident that there is more than 1 T2 spin-spin relaxation time constant, so the relaxation curve will be fitted with two T2 components.</p> <pre><code>#T1rho fitting\n\nfig, ax = plt.subplots()\noutput_lines = []\n# Define a list of tuples for the two sets of intensities\nintensity_sets = [\n    (simps_ints, 'Simps Area', 'Guess Curve', 'Fitted Curve', 'r'),\n    (abs_ints, 'Absolute Intensities', 'Guess Abs Int Curve', 'Fitted Curve Absolute Intensity', 'b')\n]\n\n\n# Initial guess parameters\n\nT1_guess = 10.6 * 10**-3\n\nT2_guess = 0.1 * 10**-3\n\n\n\n\n\nfor i, (ints, label, guess_label, fitted_label, color) in enumerate(intensity_sets):\n    if i ==0:\n        # A_guess = np.max(ints)\n        A_guess = 747197159\n\n        C_guess = 0.8\n\n        D_guess = 0.2\n\n\n\n    # Scatter plot\n        # ax.scatter(vd_list, ints, color=color, label=label)\n    #scatter plot with marker having no face color\n        ax.scatter(vd_list, ints, color=color, marker='o', facecolors='none', label=label)\n\n    # Guess curve\n        guess_integrated_int = t1.di_expdec(vd_list, T1_guess, T2_guess, A_guess, C_guess, D_guess)\n        # guess_integrated_int = t1.expdec(vd_list, T1_guess, T2_guess, T3_guess, A_guess, B_guess)\n\n        # ax.plot(vd_list, guess_integrated_int, color='brown', linestyle='--', label=guess_label, alpha=0.9)\n\n    # Fit the data\n        popt, pcov = curve_fit(t1.di_expdec, vd_list, ints, p0=[T1_guess,T2_guess, A_guess, C_guess, D_guess])\n\n    # Save the fitted params and uncertainties\n        T1_fitted, T2_fitted, A_fitted, C_fitted, D_fitted = popt\n        T1_unc, T2_unc, A_unc, C_unc, D_unc = np.sqrt(np.diag(pcov))\n\n        #define T1 and T2\n        component_1 = A_fitted *  (C_fitted)*np.exp(-vd_list/T1_fitted)\n\n        component_2 = A_fitted *  (D_fitted)*np.exp(-vd_list/T2_fitted)\n\n\n\n    # Extract the fitted curve\n\n        fitted_curve = t1.di_expdec(vd_list,T1_fitted, T2_fitted, A_fitted, C_fitted, D_fitted)\n        ax.plot(vd_list, fitted_curve, linestyle='-', color=color, label=fitted_label)\n        # ax.scatter(vd_list, fitted_curve, color='black', marker='o', facecolors='none', label=fitted_label)\n        ax.plot(vd_list, component_1, linestyle='--', color='black', alpha=0.5, label='component_1')\n        ax.plot(vd_list, component_2, linestyle='--', color='blue', alpha=0.5, label='component_2')\n\n\n\n\n    # print the fitted parameters and uncertainties\n        print(f'T1_{label.lower().replace(\" \", \"_\")}: {T1_fitted} \u00b1 {T1_unc}')\n        print(f'T2_{label.lower().replace(\" \", \"_\")}: {T2_fitted} \u00b1 {T2_unc}')\n\n\n\n        print(f'A_{label.lower().replace(\" \", \"_\")}: {A_fitted} \u00b1 {A_unc}')\n        print(f'D_{label.lower().replace(\" \", \"_\")}: {D_fitted} \u00b1 {D_unc}')\n        print(f'C_{label.lower().replace(\" \", \"_\")}: {C_fitted} \u00b1 {C_unc}')\n\n\n    # #Format the string and append fitted parameters\n\n        output_lines.append(f'M0_{label.lower().replace(\" \", \"_\")}: {A_fitted} \u00b1 {A_unc}\\n')\n        output_lines.append(f'T1_{label.lower().replace(\" \", \"_\")}: {T1_fitted} \u00b1 {T1_unc}\\n')\n        output_lines.append(f'T2_{label.lower().replace(\" \", \"_\")}: {T2_fitted} \u00b1 {T2_unc}\\n')\n\n\n\n        output_lines.append(f'D_{label.lower().replace(\" \", \"_\")}: {D_fitted} \u00b1 {D_unc}\\n')\n        output_lines.append(f'C_{label.lower().replace(\" \", \"_\")}: {C_fitted} \u00b1 {C_unc}\\n')\n\n        #save the fitted params and uncertainties in a text file\n        with open(filepath+'di_exp_fitted_params.txt', 'w') as f:\n            f.writelines(output_lines)\n\n\n# ax.semilogy()\nax.semilogx()\nax.legend(loc='best', frameon=False)\nax.set_xlabel(r'$\\tau$ (s)')\nax.set_ylabel('Intensity (arbitrary unit)')\n\n\n#plot the covariance matrix in another figure and label the axes with the fitted parameters\n\n\nplt.savefig(filepath+'di_exp_T1_fitting.svg', bbox_inches='tight', transparent=True)\nplt.tight_layout()\nfig, ax = plt.subplots()\nim = ax.imshow(np.log(np.abs(pcov)))\nax.set_xticks(np.arange(len(popt)))\nax.set_yticks(np.arange(len(popt)))\nax.set_xticklabels(['T1', 'T2', 'A', 'C', 'D'])\nax.set_yticklabels(['T1', 'T2', 'A', 'C', 'D'])\nplt.colorbar(im)\nplt.show()\nplt.clf()\nplt.close()\n</code></pre> <pre>\n<code>T1_simps_area: 0.0004946263985536798 \u00b1 0.00020040283490398923\nT2_simps_area: 4.848011749380796e-05 \u00b1 1.9614511482538942e-05\nA_simps_area: 3438254710.8369365 \u00b1 2.804566531639265e+16\nD_simps_area: 12.979705489998619 \u00b1 106204644.62067372\nC_simps_area: 5.1491745318078905 \u00b1 42135028.85234811\n</code>\n</pre> <p>The nucleus studied here is <sup>7</sup>Li and the diffusing Li species have almost similar relaxation times, which is evident from the T2 relaxation time constants and the covariance matrix plot.</p>"},{"location":"user_guide/T2_cpmg_analysis.html#import-the-necessary-libraries","title":"Import the necessary libraries","text":""},{"location":"user_guide/T2_cpmg_analysis.html#specify-path-to-the-data-file-and-ensure-that-is-appended-to-the-end-of-the-path","title":"specify path to the data file and ensure that \"\\\\\" is appended to the end of the path","text":"<ul> <li>create an instance t1 of T1Functions</li> </ul>"},{"location":"user_guide/T2_cpmg_analysis.html#read-and-convert-bruker-nmr-data-to-nmrpipe-and-csdm-formats-read_and_convert_bruker_data","title":"Read and convert Bruker NMR data to NMRPipe and CSDM formats: read_and_convert_bruker_data.","text":"<p>The function automatically detects and loads the variable delay list (vdlist, vplist, vclist) used in the experiment. In this case, the vclist is loaded, but vdlist terminology will be used.</p> <ul> <li>Note: the vclist contains the variable count and needs to be converted to time delay -- this will be explained in a later stage.</li> </ul> <p>It returns a tuple containing three elements: a list of 1D NMR (spectra), the variable delay list (vd_list), and the complete dataset in CSDM format (csdm_ds)</p>"},{"location":"user_guide/T2_cpmg_analysis.html#process-the-returned-1d-nmr-spectra","title":"Process the returned 1D NMR spectra","text":"<ul> <li>apply the Gaussian apodisation (fwhm)</li> <li>zero-filling for increased digital resolution (zero_fill_factor)</li> <li>0<sup>th</sup> order phase correction (ph0)</li> <li>1<sup>st</sup> order phase correction (ph1) -- this phase correction is a bit nuanced and so far, a value of 0 - 0.6 \u00b0 has worked quite well: see the \"Understanding Phasing\" example under User Guide</li> <li>In applying the 1<sup>st</sup> order correction, you would have to experiment with the mentioned values to obtain a pure absorption line-shape signal</li> </ul>"},{"location":"user_guide/T2_cpmg_analysis.html#find-the-area-under-the-peak-of-interest-using-the-integrate_spectrum_region-function","title":"Find the area under the peak of interest using the <code>integrate_spectrum_region()</code> function","text":"<p>The integration function employed here integrate each spectrum using trapezoid and simpson function, respectively. ppm_start and ppm_end need to be defined as the starting and ending ppm region needed to be integrated.  The integrated area of each spectrum is appended to trapz_ints and simps_ints, respectively. x_ and y_regions are regions of integration in the spectra -- needed for visuals.</p> <ul> <li>There is no difference between trapz and simps, so you would have to use either of the two in a later stage</li> </ul>"},{"location":"user_guide/T2_cpmg_analysis.html#plot_spectra_and_zoom-function","title":"plot_spectra_and_zoom() function","text":"<ul> <li>creates plots of NMR spectra with both full view and zoomed regions (max and min x zoom)</li> <li>highlights the integrated x_ and y_regions on the zoomed plot</li> <li>returns maximum intensities from each spectrum (abs_ints): relevant for relaxometry just like integrated areas contained in trapz_ints and simps_ints</li> </ul>"},{"location":"user_guide/T2_cpmg_analysis.html#convert-vd-list-to-numpy-array-and-ensure-that-the-list-and-extracted-intensities-and-areas-are-of-the-same-length","title":"Convert vd list to numpy array and ensure that the list and extracted intensities and areas are of the same length","text":"<ul> <li>The variable count list (n) imported from the file_path is converted to a numpy array</li> <li>The conversion factor 2 x D2 is applied to convert counts to time (seconds)</li> <li>where [D2 - \u03c0 - D2]<sub>n</sub> is used for this conversion<ul> <li>4.86 \u03bcs delay i.e. D2 is used in the experiment and n corresponds to the variable count list containerised in the vdlist variable</li> </ul> </li> <li>To ensure consistency, the simps_ints and abs_ints are sliced to match the length of vd_list, since sometimes the experiment is stopped when the NMR user observes that the system has completely relaxed </li> </ul> <p>Note, D2 is labelled D20 in Bruker. </p>"},{"location":"user_guide/T2_cpmg_analysis.html#viusalise-the-list-and-the-extracted-intensities-and-areas","title":"Viusalise the list and the extracted intensities and areas","text":"<ul> <li>the extracted areas from either trapz or simps integration and extracted max intensities of each spectrum are plotted against corresponding time in vd_list</li> </ul>"},{"location":"user_guide/T2_cpmg_analysis.html#single-exponential-fitting","title":"Single exponential fitting","text":""},{"location":"user_guide/T2_cpmg_analysis.html#multiple-exponential-fitting","title":"Multiple exponential fitting","text":""},{"location":"user_guide/understanding_phasing.html","title":"Understanding phasing","text":"<pre><code>import sys\n\nfrom scipy.optimize import curve_fit\n\nsys.path.append(\"../../src\")\n\nfrom relaxometrynmr.core import T1Functions\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\n</code></pre> <pre><code>filepath = r\"..\\..\\data\\T1_data\\1\\\\\"\n\nt1 = T1Functions(filepath)\n</code></pre> <pre><code>spectra, vd_list, csdm_ds = t1.read_and_convert_bruker_data(filepath)\n</code></pre> <pre><code>df = pd.DataFrame(np.arange(0, 0.6, 0.01), columns=['ph1 Values'])\n\nprint(df.head())\n</code></pre> <pre>\n<code>   ph1 Values\n0        0.00\n1        0.01\n2        0.02\n3        0.03\n4        0.04\n</code>\n</pre> <p>So, we will be using 59 values of ph1 to phase the spectrum, and you will be the judge of how well the phase correction works.</p> <pre><code>phased_spectra = []\nfor i, spectrum in enumerate(spectra):\n    if i == 14:\n        for ph1 in np.arange(0, 0.6, 0.01):\n            exp_spectrum = t1.process_spectrum(spectrum, fwhm = \"500 Hz\", zero_fill_factor = 10, ph0=50, ph1=ph1)\n            phased_spectra.append(exp_spectrum)\n    else:\n        continue\n</code></pre> <pre><code>trapz_ints = []\nsimps_ints = []\nx_regions = []\ny_regions = []\nint_uncs = []\n\nfor i, exp_spectrum in enumerate(phased_spectra):\n    trapz_int, simps_int, x_region, y_region, int_unc = t1.integrate_spectrum_region(exp_spectrum, ppm_start=500, ppm_end=650)\n    trapz_ints.append(trapz_int)\n    simps_ints.append(simps_int)\n    x_regions.append(x_region)\n    y_regions.append(y_region)\n    int_uncs.append(int_unc)\n</code></pre> <pre><code>max_x_zoom = 1000\n\nmin_x_zoom = 200\n\nabs_ints = t1.plot_spectra_and_zoomed_regions(phased_spectra, x_regions, y_regions, max_x_zoom, min_x_zoom)\n</code></pre>"},{"location":"user_guide/understanding_phasing.html#import-the-necessary-libraries","title":"Import the necessary libraries","text":""},{"location":"user_guide/understanding_phasing.html#specify-path-to-the-data-file-and-ensure-that-is-appended-to-the-end-of-the-path","title":"specify path to the data file and ensure that \"\\\\\" is appended to the end of the path","text":"<ul> <li>create an instance t1 of T1Functions</li> </ul>"},{"location":"user_guide/understanding_phasing.html#read-and-convert-bruker-nmr-data-to-nmrpipe-and-csdm-formats-read_and_convert_bruker_data","title":"Read and convert Bruker NMR data to NMRPipe and CSDM formats: read_and_convert_bruker_data.","text":"<p>The function automatically detects and loads the variable delay list (vdlist, vplist, vclist) used in the experiment.</p> <p>It returns a tuple containing three elements: a list of 1D NMR (spectra), the variable delay list (vd_list), and the complete dataset in CSDM format (csdm_ds)</p>"},{"location":"user_guide/understanding_phasing.html#process-the-returned-1d-nmr-spectra","title":"Process the returned 1D NMR spectra","text":"<ul> <li>apply the Gaussian apodisation (fwhm)</li> <li>zero-filling for increased digital resolution (zero_fill_factor)</li> <li>0<sup>th</sup> order phase correction (ph0)</li> <li>1<sup>st</sup> order phase correction (ph1) -- this phase correction is a bit nuanced and so far, a value of 0 - 0.6 \u00b0 has worked quite well</li> <li>Here we will different ph1 values to see how this phasing works, showing the users how to pick a good value of ph1</li> </ul>"}]}